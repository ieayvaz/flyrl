

     JSBSim Flight Dynamics Model v1.2.1 [GitHub build 1348/commit 9b95d1b5ccff59916c79a0e3eb8f548377910598] Mar  2 2025 15:20:26
            [JSBSim-ML v2.0]

JSBSim startup beginning ...

Using cpu device
Logging to runs/sqst8wom/PPO_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 121      |
|    ep_rew_mean     | 3.97     |
| time/              |          |
|    fps             | 110      |
|    iterations      | 1        |
|    time_elapsed    | 4        |
|    total_timesteps | 512      |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 107          |
|    ep_rew_mean          | -17.8        |
| time/                   |              |
|    fps                  | 104          |
|    iterations           | 2            |
|    time_elapsed         | 9            |
|    total_timesteps      | 1024         |
| train/                  |              |
|    approx_kl            | 2.017757e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0139      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 16.5         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000217    |
|    value_loss           | 17.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 85.5         |
|    ep_rew_mean          | -30.8        |
| time/                   |              |
|    fps                  | 96           |
|    iterations           | 3            |
|    time_elapsed         | 15           |
|    total_timesteps      | 1536         |
| train/                  |              |
|    approx_kl            | 7.887138e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.00983     |
|    learning_rate        | 1.9e-05      |
|    loss                 | 205          |
|    n_updates            | 20           |
|    policy_gradient_loss | -7.13e-05    |
|    value_loss           | 148          |
------------------------------------------
Eval num_timesteps=2048, episode_reward=-31.37 +/- 41.29
Episode length: 92.00 +/- 37.91
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 92            |
|    mean_reward          | -31.4         |
| time/                   |               |
|    total_timesteps      | 2048          |
| train/                  |               |
|    approx_kl            | 2.4653273e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00197       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 150           |
|    n_updates            | 30            |
|    policy_gradient_loss | -8.41e-05     |
|    value_loss           | 377           |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.1     |
|    ep_rew_mean     | -28.8    |
| time/              |          |
|    fps             | 74       |
|    iterations      | 4        |
|    time_elapsed    | 27       |
|    total_timesteps | 2048     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 89.6          |
|    ep_rew_mean          | -23.2         |
| time/                   |               |
|    fps                  | 78            |
|    iterations           | 5             |
|    time_elapsed         | 32            |
|    total_timesteps      | 2560          |
| train/                  |               |
|    approx_kl            | 1.1648168e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.000718     |
|    learning_rate        | 1.9e-05       |
|    loss                 | 763           |
|    n_updates            | 40            |
|    policy_gradient_loss | -8.17e-05     |
|    value_loss           | 294           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 90.7          |
|    ep_rew_mean          | -21.8         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 6             |
|    time_elapsed         | 38            |
|    total_timesteps      | 3072          |
| train/                  |               |
|    approx_kl            | 1.2664357e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00879      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 115           |
|    n_updates            | 50            |
|    policy_gradient_loss | -0.000313     |
|    value_loss           | 135           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 89.6          |
|    ep_rew_mean          | -23.8         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 7             |
|    time_elapsed         | 43            |
|    total_timesteps      | 3584          |
| train/                  |               |
|    approx_kl            | 1.5364029e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00624      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 35.4          |
|    n_updates            | 60            |
|    policy_gradient_loss | -0.000157     |
|    value_loss           | 47.5          |
-------------------------------------------
Eval num_timesteps=4096, episode_reward=-29.00 +/- 36.37
Episode length: 97.62 +/- 33.18
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 97.6         |
|    mean_reward          | -29          |
| time/                   |              |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 7.132767e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00122      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 292          |
|    n_updates            | 70           |
|    policy_gradient_loss | -3.5e-05     |
|    value_loss           | 218          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 91.8     |
|    ep_rew_mean     | -21.7    |
| time/              |          |
|    fps             | 73       |
|    iterations      | 8        |
|    time_elapsed    | 55       |
|    total_timesteps | 4096     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.2          |
|    ep_rew_mean          | -20.1         |
| time/                   |               |
|    fps                  | 76            |
|    iterations           | 9             |
|    time_elapsed         | 60            |
|    total_timesteps      | 4608          |
| train/                  |               |
|    approx_kl            | 3.8825325e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0034        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 64.5          |
|    n_updates            | 80            |
|    policy_gradient_loss | -0.000455     |
|    value_loss           | 108           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.2          |
|    ep_rew_mean          | -18.5         |
| time/                   |               |
|    fps                  | 78            |
|    iterations           | 10            |
|    time_elapsed         | 65            |
|    total_timesteps      | 5120          |
| train/                  |               |
|    approx_kl            | 3.8625905e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0067        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 8.56          |
|    n_updates            | 90            |
|    policy_gradient_loss | -0.000403     |
|    value_loss           | 11.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 97.3          |
|    ep_rew_mean          | -17.9         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 11            |
|    time_elapsed         | 70            |
|    total_timesteps      | 5632          |
| train/                  |               |
|    approx_kl            | 3.9238133e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0141       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 22.4          |
|    n_updates            | 100           |
|    policy_gradient_loss | -0.000346     |
|    value_loss           | 27.9          |
-------------------------------------------
Eval num_timesteps=6144, episode_reward=-33.07 +/- 49.97
Episode length: 92.62 +/- 42.25
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 92.6         |
|    mean_reward          | -33.1        |
| time/                   |              |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 1.801108e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.000223     |
|    learning_rate        | 1.9e-05      |
|    loss                 | 184          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.000257    |
|    value_loss           | 97.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95.8     |
|    ep_rew_mean     | -19      |
| time/              |          |
|    fps             | 74       |
|    iterations      | 12       |
|    time_elapsed    | 82       |
|    total_timesteps | 6144     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 97.3         |
|    ep_rew_mean          | -17.1        |
| time/                   |              |
|    fps                  | 75           |
|    iterations           | 13           |
|    time_elapsed         | 88           |
|    total_timesteps      | 6656         |
| train/                  |              |
|    approx_kl            | 2.724235e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.018       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 182          |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.000147    |
|    value_loss           | 180          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.8          |
|    ep_rew_mean          | -17.9         |
| time/                   |               |
|    fps                  | 76            |
|    iterations           | 14            |
|    time_elapsed         | 93            |
|    total_timesteps      | 7168          |
| train/                  |               |
|    approx_kl            | 1.0537915e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00523      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 38.3          |
|    n_updates            | 130           |
|    policy_gradient_loss | -0.000177     |
|    value_loss           | 41            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 98.2         |
|    ep_rew_mean          | -15.2        |
| time/                   |              |
|    fps                  | 77           |
|    iterations           | 15           |
|    time_elapsed         | 99           |
|    total_timesteps      | 7680         |
| train/                  |              |
|    approx_kl            | 2.338551e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00087      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 46           |
|    n_updates            | 140          |
|    policy_gradient_loss | -7.24e-05    |
|    value_loss           | 118          |
------------------------------------------
Eval num_timesteps=8192, episode_reward=-30.29 +/- 79.50
Episode length: 74.62 +/- 49.60
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 74.6          |
|    mean_reward          | -30.3         |
| time/                   |               |
|    total_timesteps      | 8192          |
| train/                  |               |
|    approx_kl            | 1.2407545e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.000277      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 254           |
|    n_updates            | 150           |
|    policy_gradient_loss | -5.35e-05     |
|    value_loss           | 538           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 98.6     |
|    ep_rew_mean     | -14.4    |
| time/              |          |
|    fps             | 75       |
|    iterations      | 16       |
|    time_elapsed    | 109      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.7          |
|    ep_rew_mean          | -12.9         |
| time/                   |               |
|    fps                  | 76            |
|    iterations           | 17            |
|    time_elapsed         | 114           |
|    total_timesteps      | 8704          |
| train/                  |               |
|    approx_kl            | 1.5962403e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.000963     |
|    learning_rate        | 1.9e-05       |
|    loss                 | 137           |
|    n_updates            | 160           |
|    policy_gradient_loss | -0.000208     |
|    value_loss           | 104           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -12.9         |
| time/                   |               |
|    fps                  | 77            |
|    iterations           | 18            |
|    time_elapsed         | 119           |
|    total_timesteps      | 9216          |
| train/                  |               |
|    approx_kl            | 1.4479854e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00422      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 37.4          |
|    n_updates            | 170           |
|    policy_gradient_loss | -0.000302     |
|    value_loss           | 45.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99            |
|    ep_rew_mean          | -13.8         |
| time/                   |               |
|    fps                  | 78            |
|    iterations           | 19            |
|    time_elapsed         | 124           |
|    total_timesteps      | 9728          |
| train/                  |               |
|    approx_kl            | 5.1221577e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0164        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 22.4          |
|    n_updates            | 180           |
|    policy_gradient_loss | -7.71e-05     |
|    value_loss           | 100           |
-------------------------------------------
Eval num_timesteps=10240, episode_reward=-30.37 +/- 49.48
Episode length: 97.62 +/- 32.41
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 97.6          |
|    mean_reward          | -30.4         |
| time/                   |               |
|    total_timesteps      | 10240         |
| train/                  |               |
|    approx_kl            | 9.8073855e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00272       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 21.1          |
|    n_updates            | 190           |
|    policy_gradient_loss | -0.000644     |
|    value_loss           | 67.2          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.4     |
|    ep_rew_mean     | -13.7    |
| time/              |          |
|    fps             | 75       |
|    iterations      | 20       |
|    time_elapsed    | 136      |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96.9         |
|    ep_rew_mean          | -15.2        |
| time/                   |              |
|    fps                  | 76           |
|    iterations           | 21           |
|    time_elapsed         | 140          |
|    total_timesteps      | 10752        |
| train/                  |              |
|    approx_kl            | 6.112293e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.00118     |
|    learning_rate        | 1.9e-05      |
|    loss                 | 9.93         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.000254    |
|    value_loss           | 12.5         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -12.2        |
| time/                   |              |
|    fps                  | 77           |
|    iterations           | 22           |
|    time_elapsed         | 145          |
|    total_timesteps      | 11264        |
| train/                  |              |
|    approx_kl            | 9.170151e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0073      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 20.2         |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.000148    |
|    value_loss           | 232          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 102         |
|    ep_rew_mean          | -12         |
| time/                   |             |
|    fps                  | 78          |
|    iterations           | 23          |
|    time_elapsed         | 149         |
|    total_timesteps      | 11776       |
| train/                  |             |
|    approx_kl            | 9.09681e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.1        |
|    explained_variance   | -0.00853    |
|    learning_rate        | 1.9e-05     |
|    loss                 | 57.8        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.000228   |
|    value_loss           | 165         |
-----------------------------------------
Eval num_timesteps=12288, episode_reward=-42.86 +/- 56.69
Episode length: 66.00 +/- 55.45
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 66            |
|    mean_reward          | -42.9         |
| time/                   |               |
|    total_timesteps      | 12288         |
| train/                  |               |
|    approx_kl            | 6.5925997e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00101       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 184           |
|    n_updates            | 230           |
|    policy_gradient_loss | -5.19e-05     |
|    value_loss           | 268           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | -13      |
| time/              |          |
|    fps             | 77       |
|    iterations      | 24       |
|    time_elapsed    | 157      |
|    total_timesteps | 12288    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.9          |
|    ep_rew_mean          | -14.3         |
| time/                   |               |
|    fps                  | 78            |
|    iterations           | 25            |
|    time_elapsed         | 162           |
|    total_timesteps      | 12800         |
| train/                  |               |
|    approx_kl            | 2.3633824e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00406      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 20.1          |
|    n_updates            | 240           |
|    policy_gradient_loss | -0.000265     |
|    value_loss           | 69.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -12.7         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 26            |
|    time_elapsed         | 167           |
|    total_timesteps      | 13312         |
| train/                  |               |
|    approx_kl            | 6.5368367e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00467      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 50.2          |
|    n_updates            | 250           |
|    policy_gradient_loss | -0.000125     |
|    value_loss           | 119           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -11.7         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 27            |
|    time_elapsed         | 172           |
|    total_timesteps      | 13824         |
| train/                  |               |
|    approx_kl            | 4.2044558e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00763      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 34.7          |
|    n_updates            | 260           |
|    policy_gradient_loss | -0.00013      |
|    value_loss           | 105           |
-------------------------------------------
Eval num_timesteps=14336, episode_reward=-34.94 +/- 49.14
Episode length: 93.75 +/- 40.33
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 93.8          |
|    mean_reward          | -34.9         |
| time/                   |               |
|    total_timesteps      | 14336         |
| train/                  |               |
|    approx_kl            | 4.1586114e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00627       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 108           |
|    n_updates            | 270           |
|    policy_gradient_loss | -0.000564     |
|    value_loss           | 89.4          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 103      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    fps             | 78       |
|    iterations      | 28       |
|    time_elapsed    | 183      |
|    total_timesteps | 14336    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 102          |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 79           |
|    iterations           | 29           |
|    time_elapsed         | 187          |
|    total_timesteps      | 14848        |
| train/                  |              |
|    approx_kl            | 7.905834e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0114      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 25.1         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.000768    |
|    value_loss           | 28           |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 100           |
|    ep_rew_mean          | -13.2         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 30            |
|    time_elapsed         | 192           |
|    total_timesteps      | 15360         |
| train/                  |               |
|    approx_kl            | 1.3685785e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00717       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 151           |
|    n_updates            | 290           |
|    policy_gradient_loss | -5.74e-05     |
|    value_loss           | 178           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -12.8        |
| time/                   |              |
|    fps                  | 80           |
|    iterations           | 31           |
|    time_elapsed         | 197          |
|    total_timesteps      | 15872        |
| train/                  |              |
|    approx_kl            | 7.943949e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00403      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 249          |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.000144    |
|    value_loss           | 211          |
------------------------------------------
Eval num_timesteps=16384, episode_reward=-36.47 +/- 46.03
Episode length: 94.50 +/- 39.67
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 94.5         |
|    mean_reward          | -36.5        |
| time/                   |              |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0001238106 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0104      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 9.15         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.000576    |
|    value_loss           | 10.6         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 78       |
|    iterations      | 32       |
|    time_elapsed    | 208      |
|    total_timesteps | 16384    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -12.9         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 33            |
|    time_elapsed         | 212           |
|    total_timesteps      | 16896         |
| train/                  |               |
|    approx_kl            | 1.2738165e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00458      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 280           |
|    n_updates            | 320           |
|    policy_gradient_loss | -6.47e-05     |
|    value_loss           | 182           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -12.6        |
| time/                   |              |
|    fps                  | 79           |
|    iterations           | 34           |
|    time_elapsed         | 217          |
|    total_timesteps      | 17408        |
| train/                  |              |
|    approx_kl            | 2.964749e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.00357     |
|    learning_rate        | 1.9e-05      |
|    loss                 | 27.9         |
|    n_updates            | 330          |
|    policy_gradient_loss | -4.39e-05    |
|    value_loss           | 110          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -14.4         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 35            |
|    time_elapsed         | 222           |
|    total_timesteps      | 17920         |
| train/                  |               |
|    approx_kl            | 2.2109947e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00254      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 106           |
|    n_updates            | 340           |
|    policy_gradient_loss | -0.000382     |
|    value_loss           | 214           |
-------------------------------------------
Eval num_timesteps=18432, episode_reward=-50.87 +/- 59.34
Episode length: 69.00 +/- 48.29
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 69            |
|    mean_reward          | -50.9         |
| time/                   |               |
|    total_timesteps      | 18432         |
| train/                  |               |
|    approx_kl            | 1.9918662e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00195       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 131           |
|    n_updates            | 350           |
|    policy_gradient_loss | -5.81e-05     |
|    value_loss           | 181           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | -15.1    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 36       |
|    time_elapsed    | 231      |
|    total_timesteps | 18432    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -15.7         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 37            |
|    time_elapsed         | 236           |
|    total_timesteps      | 18944         |
| train/                  |               |
|    approx_kl            | 2.5168993e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.000535      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 185           |
|    n_updates            | 360           |
|    policy_gradient_loss | -1.36e-05     |
|    value_loss           | 173           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -15.3         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 38            |
|    time_elapsed         | 241           |
|    total_timesteps      | 19456         |
| train/                  |               |
|    approx_kl            | 2.8835027e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0223        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 9.6           |
|    n_updates            | 370           |
|    policy_gradient_loss | -0.000196     |
|    value_loss           | 12.7          |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 104            |
|    ep_rew_mean          | -13.2          |
| time/                   |                |
|    fps                  | 80             |
|    iterations           | 39             |
|    time_elapsed         | 246            |
|    total_timesteps      | 19968          |
| train/                  |                |
|    approx_kl            | 1.10114925e-05 |
|    clip_fraction        | 0              |
|    clip_range           | 0.1            |
|    entropy_loss         | -1.1           |
|    explained_variance   | 0.00804        |
|    learning_rate        | 1.9e-05        |
|    loss                 | 136            |
|    n_updates            | 380            |
|    policy_gradient_loss | -0.000201      |
|    value_loss           | 109            |
--------------------------------------------
Eval num_timesteps=20480, episode_reward=-58.70 +/- 47.69
Episode length: 62.50 +/- 50.01
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 62.5         |
|    mean_reward          | -58.7        |
| time/                   |              |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.971749e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.00575     |
|    learning_rate        | 1.9e-05      |
|    loss                 | 22.1         |
|    n_updates            | 390          |
|    policy_gradient_loss | -8.63e-05    |
|    value_loss           | 40           |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | -12.7    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 40       |
|    time_elapsed    | 256      |
|    total_timesteps | 20480    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 105           |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 41            |
|    time_elapsed         | 261           |
|    total_timesteps      | 20992         |
| train/                  |               |
|    approx_kl            | 2.5038025e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00583       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 127           |
|    n_updates            | 400           |
|    policy_gradient_loss | -0.000405     |
|    value_loss           | 134           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 105          |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 80           |
|    iterations           | 42           |
|    time_elapsed         | 265          |
|    total_timesteps      | 21504        |
| train/                  |              |
|    approx_kl            | 1.842447e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00691      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 182          |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.000315    |
|    value_loss           | 206          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 105           |
|    ep_rew_mean          | -10.6         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 43            |
|    time_elapsed         | 270           |
|    total_timesteps      | 22016         |
| train/                  |               |
|    approx_kl            | 1.4231307e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.000402      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 133           |
|    n_updates            | 420           |
|    policy_gradient_loss | -0.000156     |
|    value_loss           | 88            |
-------------------------------------------
Eval num_timesteps=22528, episode_reward=-8.60 +/- 33.80
Episode length: 115.50 +/- 13.45
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 116           |
|    mean_reward          | -8.6          |
| time/                   |               |
|    total_timesteps      | 22528         |
| train/                  |               |
|    approx_kl            | 2.7954811e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00413       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 701           |
|    n_updates            | 430           |
|    policy_gradient_loss | -7.12e-05     |
|    value_loss           | 638           |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 107      |
|    ep_rew_mean     | -7.82    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 44       |
|    time_elapsed    | 283      |
|    total_timesteps | 22528    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 107           |
|    ep_rew_mean          | -7.87         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 45            |
|    time_elapsed         | 288           |
|    total_timesteps      | 23040         |
| train/                  |               |
|    approx_kl            | 0.00017342262 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0302        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 27.2          |
|    n_updates            | 440           |
|    policy_gradient_loss | -0.000711     |
|    value_loss           | 18.3          |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 110         |
|    ep_rew_mean          | -5.57       |
| time/                   |             |
|    fps                  | 80          |
|    iterations           | 46          |
|    time_elapsed         | 293         |
|    total_timesteps      | 23552       |
| train/                  |             |
|    approx_kl            | 9.24553e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.1        |
|    explained_variance   | 0.0012      |
|    learning_rate        | 1.9e-05     |
|    loss                 | 7.62        |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.000642   |
|    value_loss           | 17.6        |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 109           |
|    ep_rew_mean          | -6.86         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 47            |
|    time_elapsed         | 298           |
|    total_timesteps      | 24064         |
| train/                  |               |
|    approx_kl            | 5.9506507e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.041         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 18.9          |
|    n_updates            | 460           |
|    policy_gradient_loss | -0.000643     |
|    value_loss           | 21.5          |
-------------------------------------------
Eval num_timesteps=24576, episode_reward=-50.02 +/- 40.72
Episode length: 78.88 +/- 46.82
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 78.9         |
|    mean_reward          | -50          |
| time/                   |              |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 8.745235e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.00484     |
|    learning_rate        | 1.9e-05      |
|    loss                 | 278          |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.000175    |
|    value_loss           | 340          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 107      |
|    ep_rew_mean     | -8.82    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 48       |
|    time_elapsed    | 309      |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 107           |
|    ep_rew_mean          | -8.63         |
| time/                   |               |
|    fps                  | 79            |
|    iterations           | 49            |
|    time_elapsed         | 313           |
|    total_timesteps      | 25088         |
| train/                  |               |
|    approx_kl            | 1.1204509e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0004        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 182           |
|    n_updates            | 480           |
|    policy_gradient_loss | -0.000231     |
|    value_loss           | 266           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 50            |
|    time_elapsed         | 318           |
|    total_timesteps      | 25600         |
| train/                  |               |
|    approx_kl            | 1.8825172e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0127       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 16.2          |
|    n_updates            | 490           |
|    policy_gradient_loss | -0.000153     |
|    value_loss           | 25.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -8.78         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 51            |
|    time_elapsed         | 322           |
|    total_timesteps      | 26112         |
| train/                  |               |
|    approx_kl            | 1.2045493e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00684       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 156           |
|    n_updates            | 500           |
|    policy_gradient_loss | -8.14e-05     |
|    value_loss           | 315           |
-------------------------------------------
Eval num_timesteps=26624, episode_reward=-50.12 +/- 44.93
Episode length: 83.62 +/- 43.28
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 83.6         |
|    mean_reward          | -50.1        |
| time/                   |              |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0002515976 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00903      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 10.6         |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.00138     |
|    value_loss           | 11.8         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 52       |
|    time_elapsed    | 333      |
|    total_timesteps | 26624    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 53            |
|    time_elapsed         | 337           |
|    total_timesteps      | 27136         |
| train/                  |               |
|    approx_kl            | 1.1904631e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00478       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 195           |
|    n_updates            | 520           |
|    policy_gradient_loss | -1.55e-05     |
|    value_loss           | 198           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -8.61         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 54            |
|    time_elapsed         | 342           |
|    total_timesteps      | 27648         |
| train/                  |               |
|    approx_kl            | 4.4524204e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0216        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 154           |
|    n_updates            | 530           |
|    policy_gradient_loss | -0.000185     |
|    value_loss           | 89.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 107           |
|    ep_rew_mean          | -8.17         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 55            |
|    time_elapsed         | 347           |
|    total_timesteps      | 28160         |
| train/                  |               |
|    approx_kl            | 7.1045943e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0184        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 22            |
|    n_updates            | 540           |
|    policy_gradient_loss | -0.000161     |
|    value_loss           | 25.9          |
-------------------------------------------
Eval num_timesteps=28672, episode_reward=-7.98 +/- 36.61
Episode length: 106.38 +/- 38.69
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 106           |
|    mean_reward          | -7.98         |
| time/                   |               |
|    total_timesteps      | 28672         |
| train/                  |               |
|    approx_kl            | 0.00012382295 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0244        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 15.8          |
|    n_updates            | 550           |
|    policy_gradient_loss | -0.00061      |
|    value_loss           | 17.5          |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 106      |
|    ep_rew_mean     | -8.64    |
| time/              |          |
|    fps             | 79       |
|    iterations      | 56       |
|    time_elapsed    | 360      |
|    total_timesteps | 28672    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -8.89         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 57            |
|    time_elapsed         | 364           |
|    total_timesteps      | 29184         |
| train/                  |               |
|    approx_kl            | 1.1242228e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.000594      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 308           |
|    n_updates            | 560           |
|    policy_gradient_loss | -4.3e-05      |
|    value_loss           | 322           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -8.2          |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 58            |
|    time_elapsed         | 368           |
|    total_timesteps      | 29696         |
| train/                  |               |
|    approx_kl            | 4.8880465e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0104        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 202           |
|    n_updates            | 570           |
|    policy_gradient_loss | -0.000216     |
|    value_loss           | 175           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -8.03         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 59            |
|    time_elapsed         | 373           |
|    total_timesteps      | 30208         |
| train/                  |               |
|    approx_kl            | 1.1054799e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0333        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 37.9          |
|    n_updates            | 580           |
|    policy_gradient_loss | -6.5e-05      |
|    value_loss           | 54.8          |
-------------------------------------------
Eval num_timesteps=30720, episode_reward=-43.31 +/- 57.27
Episode length: 61.88 +/- 59.14
--------------------------------------------
| eval/                   |                |
|    mean_ep_length       | 61.9           |
|    mean_reward          | -43.3          |
| time/                   |                |
|    total_timesteps      | 30720          |
| train/                  |                |
|    approx_kl            | 0.000107305124 |
|    clip_fraction        | 0              |
|    clip_range           | 0.1            |
|    entropy_loss         | -1.1           |
|    explained_variance   | 0.0194         |
|    learning_rate        | 1.9e-05        |
|    loss                 | 20.8           |
|    n_updates            | 590            |
|    policy_gradient_loss | -0.000582      |
|    value_loss           | 19.3           |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -8.65    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 60       |
|    time_elapsed    | 382      |
|    total_timesteps | 30720    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 105           |
|    ep_rew_mean          | -8.72         |
| time/                   |               |
|    fps                  | 80            |
|    iterations           | 61            |
|    time_elapsed         | 387           |
|    total_timesteps      | 31232         |
| train/                  |               |
|    approx_kl            | 1.2206845e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0246        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 18.5          |
|    n_updates            | 600           |
|    policy_gradient_loss | -0.000208     |
|    value_loss           | 59            |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | -8.81       |
| time/                   |             |
|    fps                  | 80          |
|    iterations           | 62          |
|    time_elapsed         | 392         |
|    total_timesteps      | 31744       |
| train/                  |             |
|    approx_kl            | 3.25531e-05 |
|    clip_fraction        | 0           |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.1        |
|    explained_variance   | 0.00299     |
|    learning_rate        | 1.9e-05     |
|    loss                 | 101         |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.000535   |
|    value_loss           | 106         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -7.89         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 63            |
|    time_elapsed         | 397           |
|    total_timesteps      | 32256         |
| train/                  |               |
|    approx_kl            | 8.8368426e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0632        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 14.6          |
|    n_updates            | 620           |
|    policy_gradient_loss | -0.000824     |
|    value_loss           | 11.2          |
-------------------------------------------
Eval num_timesteps=32768, episode_reward=-41.00 +/- 57.26
Episode length: 72.88 +/- 56.23
--------------------------------------------
| eval/                   |                |
|    mean_ep_length       | 72.9           |
|    mean_reward          | -41            |
| time/                   |                |
|    total_timesteps      | 32768          |
| train/                  |                |
|    approx_kl            | 1.06883235e-05 |
|    clip_fraction        | 0              |
|    clip_range           | 0.1            |
|    entropy_loss         | -1.1           |
|    explained_variance   | 0.059          |
|    learning_rate        | 1.9e-05        |
|    loss                 | 27.6           |
|    n_updates            | 630            |
|    policy_gradient_loss | -0.000246      |
|    value_loss           | 27.5           |
--------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 107      |
|    ep_rew_mean     | -8.65    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 64       |
|    time_elapsed    | 406      |
|    total_timesteps | 32768    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 105          |
|    ep_rew_mean          | -10.8        |
| time/                   |              |
|    fps                  | 80           |
|    iterations           | 65           |
|    time_elapsed         | 411          |
|    total_timesteps      | 33280        |
| train/                  |              |
|    approx_kl            | 8.156756e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.021       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 57.8         |
|    n_updates            | 640          |
|    policy_gradient_loss | -7.4e-05     |
|    value_loss           | 45.7         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -14.3         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 66            |
|    time_elapsed         | 416           |
|    total_timesteps      | 33792         |
| train/                  |               |
|    approx_kl            | 1.2767268e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0227        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 294           |
|    n_updates            | 650           |
|    policy_gradient_loss | -5.2e-05      |
|    value_loss           | 224           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -13.7        |
| time/                   |              |
|    fps                  | 81           |
|    iterations           | 67           |
|    time_elapsed         | 421          |
|    total_timesteps      | 34304        |
| train/                  |              |
|    approx_kl            | 4.980946e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.015        |
|    learning_rate        | 1.9e-05      |
|    loss                 | 78.4         |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.000153    |
|    value_loss           | 173          |
------------------------------------------
Eval num_timesteps=34816, episode_reward=-66.14 +/- 51.00
Episode length: 67.12 +/- 40.81
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 67.1         |
|    mean_reward          | -66.1        |
| time/                   |              |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 2.536457e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00331      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 170          |
|    n_updates            | 670          |
|    policy_gradient_loss | -7.08e-05    |
|    value_loss           | 216          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    fps             | 80       |
|    iterations      | 68       |
|    time_elapsed    | 430      |
|    total_timesteps | 34816    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 102          |
|    ep_rew_mean          | -13.3        |
| time/                   |              |
|    fps                  | 81           |
|    iterations           | 69           |
|    time_elapsed         | 434          |
|    total_timesteps      | 35328        |
| train/                  |              |
|    approx_kl            | 6.810017e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0121       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 12.5         |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.000381    |
|    value_loss           | 14.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 70            |
|    time_elapsed         | 439           |
|    total_timesteps      | 35840         |
| train/                  |               |
|    approx_kl            | 5.7120807e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 19.9          |
|    n_updates            | 690           |
|    policy_gradient_loss | -0.000344     |
|    value_loss           | 15.5          |
-------------------------------------------
--------------------------------------------
| rollout/                |                |
|    ep_len_mean          | 104            |
|    ep_rew_mean          | -11.4          |
| time/                   |                |
|    fps                  | 81             |
|    iterations           | 71             |
|    time_elapsed         | 444            |
|    total_timesteps      | 36352          |
| train/                  |                |
|    approx_kl            | 1.25312945e-05 |
|    clip_fraction        | 0              |
|    clip_range           | 0.1            |
|    entropy_loss         | -1.1           |
|    explained_variance   | 0.0248         |
|    learning_rate        | 1.9e-05        |
|    loss                 | 225            |
|    n_updates            | 700            |
|    policy_gradient_loss | -0.000356      |
|    value_loss           | 174            |
--------------------------------------------
Eval num_timesteps=36864, episode_reward=-30.79 +/- 47.98
Episode length: 84.88 +/- 46.06
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 84.9          |
|    mean_reward          | -30.8         |
| time/                   |               |
|    total_timesteps      | 36864         |
| train/                  |               |
|    approx_kl            | 2.1054177e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0201        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 82.9          |
|    n_updates            | 710           |
|    policy_gradient_loss | -0.000339     |
|    value_loss           | 91.4          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 72       |
|    time_elapsed    | 454      |
|    total_timesteps | 36864    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -9.42         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 73            |
|    time_elapsed         | 458           |
|    total_timesteps      | 37376         |
| train/                  |               |
|    approx_kl            | 0.00013384072 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.012        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 13.5          |
|    n_updates            | 720           |
|    policy_gradient_loss | -0.000592     |
|    value_loss           | 21.5          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 74            |
|    time_elapsed         | 462           |
|    total_timesteps      | 37888         |
| train/                  |               |
|    approx_kl            | 1.0642689e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0154        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 142           |
|    n_updates            | 730           |
|    policy_gradient_loss | -5.67e-05     |
|    value_loss           | 540           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 75            |
|    time_elapsed         | 466           |
|    total_timesteps      | 38400         |
| train/                  |               |
|    approx_kl            | 1.2999633e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0248        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 19.6          |
|    n_updates            | 740           |
|    policy_gradient_loss | -0.000191     |
|    value_loss           | 60.3          |
-------------------------------------------
Eval num_timesteps=38912, episode_reward=-14.81 +/- 46.90
Episode length: 101.38 +/- 36.13
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 101          |
|    mean_reward          | -14.8        |
| time/                   |              |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 5.967333e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0292       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 46.8         |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.000118    |
|    value_loss           | 140          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 76       |
|    time_elapsed    | 478      |
|    total_timesteps | 38912    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -9.76         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 77            |
|    time_elapsed         | 483           |
|    total_timesteps      | 39424         |
| train/                  |               |
|    approx_kl            | 2.7092057e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0403        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 21.5          |
|    n_updates            | 760           |
|    policy_gradient_loss | -0.000266     |
|    value_loss           | 17.4          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -10.5         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 78            |
|    time_elapsed         | 487           |
|    total_timesteps      | 39936         |
| train/                  |               |
|    approx_kl            | 0.00017195556 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0689        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 23.5          |
|    n_updates            | 770           |
|    policy_gradient_loss | -0.000996     |
|    value_loss           | 16.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 103          |
|    ep_rew_mean          | -10.1        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 79           |
|    time_elapsed         | 492          |
|    total_timesteps      | 40448        |
| train/                  |              |
|    approx_kl            | 6.568129e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.141        |
|    learning_rate        | 1.9e-05      |
|    loss                 | 12.9         |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.000469    |
|    value_loss           | 10.3         |
------------------------------------------
Eval num_timesteps=40960, episode_reward=-63.54 +/- 43.95
Episode length: 62.88 +/- 47.07
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 62.9          |
|    mean_reward          | -63.5         |
| time/                   |               |
|    total_timesteps      | 40960         |
| train/                  |               |
|    approx_kl            | 1.8295716e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0797        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 40.4          |
|    n_updates            | 790           |
|    policy_gradient_loss | -0.000439     |
|    value_loss           | 45.6          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 80       |
|    time_elapsed    | 501      |
|    total_timesteps | 40960    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -10.3         |
| time/                   |               |
|    fps                  | 81            |
|    iterations           | 81            |
|    time_elapsed         | 506           |
|    total_timesteps      | 41472         |
| train/                  |               |
|    approx_kl            | 2.1411106e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0269        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 135           |
|    n_updates            | 800           |
|    policy_gradient_loss | -9.16e-05     |
|    value_loss           | 100           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 102          |
|    ep_rew_mean          | -10.2        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 82           |
|    time_elapsed         | 511          |
|    total_timesteps      | 41984        |
| train/                  |              |
|    approx_kl            | 6.698887e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0407       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 223          |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.000219    |
|    value_loss           | 187          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -10.6        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 83           |
|    time_elapsed         | 516          |
|    total_timesteps      | 42496        |
| train/                  |              |
|    approx_kl            | 6.698421e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.036        |
|    learning_rate        | 1.9e-05      |
|    loss                 | 201          |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.000154    |
|    value_loss           | 120          |
------------------------------------------
Eval num_timesteps=43008, episode_reward=-72.55 +/- 39.30
Episode length: 61.12 +/- 46.50
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 61.1          |
|    mean_reward          | -72.5         |
| time/                   |               |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 2.6242458e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0438        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 49.9          |
|    n_updates            | 830           |
|    policy_gradient_loss | -0.000329     |
|    value_loss           | 78.5          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 100      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 84       |
|    time_elapsed    | 524      |
|    total_timesteps | 43008    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 85            |
|    time_elapsed         | 528           |
|    total_timesteps      | 43520         |
| train/                  |               |
|    approx_kl            | 1.7823186e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.013         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 437           |
|    n_updates            | 840           |
|    policy_gradient_loss | -0.000114     |
|    value_loss           | 390           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -9.89         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 86            |
|    time_elapsed         | 533           |
|    total_timesteps      | 44032         |
| train/                  |               |
|    approx_kl            | 1.3195677e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0326        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 233           |
|    n_updates            | 850           |
|    policy_gradient_loss | -5.11e-05     |
|    value_loss           | 190           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 105           |
|    ep_rew_mean          | -8.68         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 87            |
|    time_elapsed         | 538           |
|    total_timesteps      | 44544         |
| train/                  |               |
|    approx_kl            | 0.00022433128 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0419       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 9.45          |
|    n_updates            | 860           |
|    policy_gradient_loss | -0.000845     |
|    value_loss           | 30            |
-------------------------------------------
Eval num_timesteps=45056, episode_reward=-4.34 +/- 32.72
Episode length: 112.75 +/- 21.83
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 113           |
|    mean_reward          | -4.34         |
| time/                   |               |
|    total_timesteps      | 45056         |
| train/                  |               |
|    approx_kl            | 3.8329745e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.014        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 156           |
|    n_updates            | 870           |
|    policy_gradient_loss | -6.97e-05     |
|    value_loss           | 201           |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -8.14    |
| time/              |          |
|    fps             | 81       |
|    iterations      | 88       |
|    time_elapsed    | 550      |
|    total_timesteps | 45056    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 105          |
|    ep_rew_mean          | -8.37        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 89           |
|    time_elapsed         | 554          |
|    total_timesteps      | 45568        |
| train/                  |              |
|    approx_kl            | 7.432536e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00962      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 851          |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.000162    |
|    value_loss           | 762          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -8.85         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 90            |
|    time_elapsed         | 559           |
|    total_timesteps      | 46080         |
| train/                  |               |
|    approx_kl            | 5.7673315e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.046         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 115           |
|    n_updates            | 890           |
|    policy_gradient_loss | -0.000121     |
|    value_loss           | 124           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 105          |
|    ep_rew_mean          | -8.17        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 91           |
|    time_elapsed         | 563          |
|    total_timesteps      | 46592        |
| train/                  |              |
|    approx_kl            | 7.712515e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0353       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 433          |
|    n_updates            | 900          |
|    policy_gradient_loss | -2.49e-05    |
|    value_loss           | 397          |
------------------------------------------
Eval num_timesteps=47104, episode_reward=-33.76 +/- 40.78
Episode length: 87.62 +/- 45.16
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 87.6          |
|    mean_reward          | -33.8         |
| time/                   |               |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 0.00012487196 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0904        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 30.7          |
|    n_updates            | 910           |
|    policy_gradient_loss | -0.0012       |
|    value_loss           | 30.3          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 92       |
|    time_elapsed    | 573      |
|    total_timesteps | 47104    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 93            |
|    time_elapsed         | 578           |
|    total_timesteps      | 47616         |
| train/                  |               |
|    approx_kl            | 2.2170134e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0111       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 277           |
|    n_updates            | 920           |
|    policy_gradient_loss | -9.73e-05     |
|    value_loss           | 269           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 103          |
|    ep_rew_mean          | -11.2        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 94           |
|    time_elapsed         | 582          |
|    total_timesteps      | 48128        |
| train/                  |              |
|    approx_kl            | 4.739617e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0326       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 163          |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.000193    |
|    value_loss           | 179          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 104          |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 95           |
|    time_elapsed         | 587          |
|    total_timesteps      | 48640        |
| train/                  |              |
|    approx_kl            | 4.525762e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0266       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 165          |
|    n_updates            | 940          |
|    policy_gradient_loss | -0.000219    |
|    value_loss           | 101          |
------------------------------------------
Eval num_timesteps=49152, episode_reward=-53.50 +/- 46.36
Episode length: 62.62 +/- 50.68
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 62.6          |
|    mean_reward          | -53.5         |
| time/                   |               |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 2.0735897e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0288        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 130           |
|    n_updates            | 950           |
|    policy_gradient_loss | -8.74e-05     |
|    value_loss           | 84.9          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -13      |
| time/              |          |
|    fps             | 82       |
|    iterations      | 96       |
|    time_elapsed    | 595      |
|    total_timesteps | 49152    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -14.9        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 97           |
|    time_elapsed         | 600          |
|    total_timesteps      | 49664        |
| train/                  |              |
|    approx_kl            | 9.892741e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0239       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 136          |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00028     |
|    value_loss           | 198          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.5          |
|    ep_rew_mean          | -17.3         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 98            |
|    time_elapsed         | 604           |
|    total_timesteps      | 50176         |
| train/                  |               |
|    approx_kl            | 1.5458791e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0539        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 251           |
|    n_updates            | 970           |
|    policy_gradient_loss | -0.000112     |
|    value_loss           | 288           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.9          |
|    ep_rew_mean          | -17.2         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 99            |
|    time_elapsed         | 609           |
|    total_timesteps      | 50688         |
| train/                  |               |
|    approx_kl            | 6.9793314e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00632      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 380           |
|    n_updates            | 980           |
|    policy_gradient_loss | 3.31e-05      |
|    value_loss           | 271           |
-------------------------------------------
Eval num_timesteps=51200, episode_reward=-41.41 +/- 32.79
Episode length: 101.50 +/- 28.35
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 102           |
|    mean_reward          | -41.4         |
| time/                   |               |
|    total_timesteps      | 51200         |
| train/                  |               |
|    approx_kl            | 0.00010571664 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0756        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 10.2          |
|    n_updates            | 990           |
|    policy_gradient_loss | -0.000507     |
|    value_loss           | 8.93          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.8     |
|    ep_rew_mean     | -19.2    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 100      |
|    time_elapsed    | 620      |
|    total_timesteps | 51200    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.2          |
|    ep_rew_mean          | -18.6         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 101           |
|    time_elapsed         | 624           |
|    total_timesteps      | 51712         |
| train/                  |               |
|    approx_kl            | 1.4225952e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.025         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 226           |
|    n_updates            | 1000          |
|    policy_gradient_loss | -1.01e-05     |
|    value_loss           | 328           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 99.3         |
|    ep_rew_mean          | -17.9        |
| time/                   |              |
|    fps                  | 83           |
|    iterations           | 102          |
|    time_elapsed         | 628          |
|    total_timesteps      | 52224        |
| train/                  |              |
|    approx_kl            | 8.124742e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0247       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 40.6         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.000174    |
|    value_loss           | 39.3         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.8          |
|    ep_rew_mean          | -18.3         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 103           |
|    time_elapsed         | 632           |
|    total_timesteps      | 52736         |
| train/                  |               |
|    approx_kl            | 3.7175138e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0395       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 8.97          |
|    n_updates            | 1020          |
|    policy_gradient_loss | -0.000322     |
|    value_loss           | 8.11          |
-------------------------------------------
Eval num_timesteps=53248, episode_reward=-29.07 +/- 34.22
Episode length: 85.62 +/- 41.03
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 85.6          |
|    mean_reward          | -29.1         |
| time/                   |               |
|    total_timesteps      | 53248         |
| train/                  |               |
|    approx_kl            | 2.9132934e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0618        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 119           |
|    n_updates            | 1030          |
|    policy_gradient_loss | -0.000118     |
|    value_loss           | 90.7          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.5     |
|    ep_rew_mean     | -17.8    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 104      |
|    time_elapsed    | 643      |
|    total_timesteps | 53248    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.6          |
|    ep_rew_mean          | -17.8         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 105           |
|    time_elapsed         | 648           |
|    total_timesteps      | 53760         |
| train/                  |               |
|    approx_kl            | 1.0895426e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.00744       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 10.6          |
|    n_updates            | 1040          |
|    policy_gradient_loss | -0.000196     |
|    value_loss           | 82.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.3          |
|    ep_rew_mean          | -17.2         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 106           |
|    time_elapsed         | 652           |
|    total_timesteps      | 54272         |
| train/                  |               |
|    approx_kl            | 1.4544814e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0822        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 48.9          |
|    n_updates            | 1050          |
|    policy_gradient_loss | -0.000277     |
|    value_loss           | 68.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -15.2         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 107           |
|    time_elapsed         | 657           |
|    total_timesteps      | 54784         |
| train/                  |               |
|    approx_kl            | 6.2839827e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0416        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 91.8          |
|    n_updates            | 1060          |
|    policy_gradient_loss | -0.000206     |
|    value_loss           | 158           |
-------------------------------------------
Eval num_timesteps=55296, episode_reward=-49.87 +/- 69.54
Episode length: 79.12 +/- 36.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 79.1         |
|    mean_reward          | -49.9        |
| time/                   |              |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 9.267172e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0202      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 5.9          |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.000481    |
|    value_loss           | 8.17         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -15.8    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 108      |
|    time_elapsed    | 667      |
|    total_timesteps | 55296    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -15.7         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 109           |
|    time_elapsed         | 672           |
|    total_timesteps      | 55808         |
| train/                  |               |
|    approx_kl            | 1.2007775e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0169        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 24.5          |
|    n_updates            | 1080          |
|    policy_gradient_loss | -0.000326     |
|    value_loss           | 22.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -15           |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 110           |
|    time_elapsed         | 677           |
|    total_timesteps      | 56320         |
| train/                  |               |
|    approx_kl            | 4.2121275e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0756       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 11.9          |
|    n_updates            | 1090          |
|    policy_gradient_loss | -0.000384     |
|    value_loss           | 13.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -16           |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 111           |
|    time_elapsed         | 681           |
|    total_timesteps      | 56832         |
| train/                  |               |
|    approx_kl            | 2.1564541e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0207        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 66.4          |
|    n_updates            | 1100          |
|    policy_gradient_loss | -0.000236     |
|    value_loss           | 107           |
-------------------------------------------
Eval num_timesteps=57344, episode_reward=-14.04 +/- 24.36
Episode length: 101.75 +/- 25.75
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 102           |
|    mean_reward          | -14           |
| time/                   |               |
|    total_timesteps      | 57344         |
| train/                  |               |
|    approx_kl            | 1.3269018e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0331        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 395           |
|    n_updates            | 1110          |
|    policy_gradient_loss | -3.13e-05     |
|    value_loss           | 220           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 103      |
|    ep_rew_mean     | -14.2    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 112      |
|    time_elapsed    | 693      |
|    total_timesteps | 57344    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 106           |
|    ep_rew_mean          | -12.1         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 113           |
|    time_elapsed         | 698           |
|    total_timesteps      | 57856         |
| train/                  |               |
|    approx_kl            | 1.4771707e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.12          |
|    learning_rate        | 1.9e-05       |
|    loss                 | 13.6          |
|    n_updates            | 1120          |
|    policy_gradient_loss | -0.000162     |
|    value_loss           | 17.3          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 106          |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 82           |
|    iterations           | 114          |
|    time_elapsed         | 703          |
|    total_timesteps      | 58368        |
| train/                  |              |
|    approx_kl            | 9.781646e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0811       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 8.92         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.000795    |
|    value_loss           | 11.9         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 106          |
|    ep_rew_mean          | -13.1        |
| time/                   |              |
|    fps                  | 83           |
|    iterations           | 115          |
|    time_elapsed         | 708          |
|    total_timesteps      | 58880        |
| train/                  |              |
|    approx_kl            | 1.484307e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0356      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 66           |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.000231    |
|    value_loss           | 92.1         |
------------------------------------------
Eval num_timesteps=59392, episode_reward=-27.76 +/- 38.06
Episode length: 77.75 +/- 46.15
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 77.8          |
|    mean_reward          | -27.8         |
| time/                   |               |
|    total_timesteps      | 59392         |
| train/                  |               |
|    approx_kl            | 1.0423828e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0486        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 293           |
|    n_updates            | 1150          |
|    policy_gradient_loss | -5.96e-05     |
|    value_loss           | 149           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 106      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 116      |
|    time_elapsed    | 718      |
|    total_timesteps | 59392    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 107           |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 117           |
|    time_elapsed         | 722           |
|    total_timesteps      | 59904         |
| train/                  |               |
|    approx_kl            | 3.3837277e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0785        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 55.9          |
|    n_updates            | 1160          |
|    policy_gradient_loss | -0.000107     |
|    value_loss           | 67.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 108           |
|    ep_rew_mean          | -9.7          |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 118           |
|    time_elapsed         | 726           |
|    total_timesteps      | 60416         |
| train/                  |               |
|    approx_kl            | 2.4326844e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0353        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 503           |
|    n_updates            | 1170          |
|    policy_gradient_loss | -0.000424     |
|    value_loss           | 333           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 107           |
|    ep_rew_mean          | -10           |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 119           |
|    time_elapsed         | 730           |
|    total_timesteps      | 60928         |
| train/                  |               |
|    approx_kl            | 1.2752134e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0827        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 101           |
|    n_updates            | 1180          |
|    policy_gradient_loss | -4.78e-05     |
|    value_loss           | 81.4          |
-------------------------------------------
Eval num_timesteps=61440, episode_reward=-2.73 +/- 39.20
Episode length: 102.75 +/- 22.46
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 103           |
|    mean_reward          | -2.73         |
| time/                   |               |
|    total_timesteps      | 61440         |
| train/                  |               |
|    approx_kl            | 4.5426423e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0134        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 48.8          |
|    n_updates            | 1190          |
|    policy_gradient_loss | -0.000189     |
|    value_loss           | 173           |
-------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 105      |
|    ep_rew_mean     | -9.45    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 120      |
|    time_elapsed    | 741      |
|    total_timesteps | 61440    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 105           |
|    ep_rew_mean          | -9.08         |
| time/                   |               |
|    fps                  | 82            |
|    iterations           | 121           |
|    time_elapsed         | 746           |
|    total_timesteps      | 61952         |
| train/                  |               |
|    approx_kl            | 2.9666116e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0331        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 663           |
|    n_updates            | 1200          |
|    policy_gradient_loss | -0.000112     |
|    value_loss           | 373           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -11.7         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 122           |
|    time_elapsed         | 751           |
|    total_timesteps      | 62464         |
| train/                  |               |
|    approx_kl            | 0.00013739662 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.00771      |
|    learning_rate        | 1.9e-05       |
|    loss                 | 9.88          |
|    n_updates            | 1210          |
|    policy_gradient_loss | -0.00101      |
|    value_loss           | 27.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -11.7         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 123           |
|    time_elapsed         | 755           |
|    total_timesteps      | 62976         |
| train/                  |               |
|    approx_kl            | 5.3143594e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0171        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 58.4          |
|    n_updates            | 1220          |
|    policy_gradient_loss | -0.000143     |
|    value_loss           | 194           |
-------------------------------------------
Eval num_timesteps=63488, episode_reward=-32.34 +/- 50.87
Episode length: 71.12 +/- 46.57
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 71.1          |
|    mean_reward          | -32.3         |
| time/                   |               |
|    total_timesteps      | 63488         |
| train/                  |               |
|    approx_kl            | 1.5457394e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0925        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 20.1          |
|    n_updates            | 1230          |
|    policy_gradient_loss | -0.000267     |
|    value_loss           | 58.1          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 103      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    fps             | 82       |
|    iterations      | 124      |
|    time_elapsed    | 765      |
|    total_timesteps | 63488    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 104          |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 83           |
|    iterations           | 125          |
|    time_elapsed         | 770          |
|    total_timesteps      | 64000        |
| train/                  |              |
|    approx_kl            | 3.890053e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0564       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 29.6         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.000505    |
|    value_loss           | 58.4         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 104           |
|    ep_rew_mean          | -12           |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 126           |
|    time_elapsed         | 775           |
|    total_timesteps      | 64512         |
| train/                  |               |
|    approx_kl            | 6.7985384e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.083         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 66.7          |
|    n_updates            | 1250          |
|    policy_gradient_loss | -0.000133     |
|    value_loss           | 93.2          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -13.3        |
| time/                   |              |
|    fps                  | 83           |
|    iterations           | 127          |
|    time_elapsed         | 780          |
|    total_timesteps      | 65024        |
| train/                  |              |
|    approx_kl            | 9.347685e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0954      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 111          |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.000123    |
|    value_loss           | 87.5         |
------------------------------------------
Eval num_timesteps=65536, episode_reward=-73.07 +/- 36.58
Episode length: 35.25 +/- 43.79
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 35.2          |
|    mean_reward          | -73.1         |
| time/                   |               |
|    total_timesteps      | 65536         |
| train/                  |               |
|    approx_kl            | 1.2797071e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0398        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 305           |
|    n_updates            | 1270          |
|    policy_gradient_loss | -0.000279     |
|    value_loss           | 245           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.6     |
|    ep_rew_mean     | -15.1    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 128      |
|    time_elapsed    | 787      |
|    total_timesteps | 65536    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 99           |
|    ep_rew_mean          | -15.7        |
| time/                   |              |
|    fps                  | 83           |
|    iterations           | 129          |
|    time_elapsed         | 791          |
|    total_timesteps      | 66048        |
| train/                  |              |
|    approx_kl            | 5.671638e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0597       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 84.6         |
|    n_updates            | 1280         |
|    policy_gradient_loss | -9.35e-05    |
|    value_loss           | 102          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 98.2         |
|    ep_rew_mean          | -17          |
| time/                   |              |
|    fps                  | 83           |
|    iterations           | 130          |
|    time_elapsed         | 795          |
|    total_timesteps      | 66560        |
| train/                  |              |
|    approx_kl            | 8.223613e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.013        |
|    learning_rate        | 1.9e-05      |
|    loss                 | 46.3         |
|    n_updates            | 1290         |
|    policy_gradient_loss | -0.000842    |
|    value_loss           | 93.2         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 97.4          |
|    ep_rew_mean          | -17.2         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 131           |
|    time_elapsed         | 800           |
|    total_timesteps      | 67072         |
| train/                  |               |
|    approx_kl            | 4.8195943e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.0674        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 202           |
|    n_updates            | 1300          |
|    policy_gradient_loss | -0.000147     |
|    value_loss           | 244           |
-------------------------------------------
Eval num_timesteps=67584, episode_reward=-35.67 +/- 64.38
Episode length: 69.12 +/- 45.11
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 69.1          |
|    mean_reward          | -35.7         |
| time/                   |               |
|    total_timesteps      | 67584         |
| train/                  |               |
|    approx_kl            | 1.0362477e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.0627        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 26.5          |
|    n_updates            | 1310          |
|    policy_gradient_loss | -0.000127     |
|    value_loss           | 48.8          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.4     |
|    ep_rew_mean     | -17.3    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 132      |
|    time_elapsed    | 809      |
|    total_timesteps | 67584    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.8          |
|    ep_rew_mean          | -18.9         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 133           |
|    time_elapsed         | 814           |
|    total_timesteps      | 68096         |
| train/                  |               |
|    approx_kl            | 3.5771634e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.115         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 14.8          |
|    n_updates            | 1320          |
|    policy_gradient_loss | -0.000222     |
|    value_loss           | 19.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.1          |
|    ep_rew_mean          | -17.4         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 134           |
|    time_elapsed         | 819           |
|    total_timesteps      | 68608         |
| train/                  |               |
|    approx_kl            | 2.4297042e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | -0.015        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 253           |
|    n_updates            | 1330          |
|    policy_gradient_loss | -4.72e-05     |
|    value_loss           | 436           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.8          |
|    ep_rew_mean          | -18.7         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 135           |
|    time_elapsed         | 823           |
|    total_timesteps      | 69120         |
| train/                  |               |
|    approx_kl            | 2.2924505e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.145         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 15.9          |
|    n_updates            | 1340          |
|    policy_gradient_loss | -9.01e-05     |
|    value_loss           | 16.2          |
-------------------------------------------
Eval num_timesteps=69632, episode_reward=-48.64 +/- 34.98
Episode length: 67.50 +/- 43.46
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 67.5         |
|    mean_reward          | -48.6        |
| time/                   |              |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 8.701149e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0613       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 138          |
|    n_updates            | 1350         |
|    policy_gradient_loss | -0.000896    |
|    value_loss           | 193          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93.1     |
|    ep_rew_mean     | -19.2    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 136      |
|    time_elapsed    | 833      |
|    total_timesteps | 69632    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93.4          |
|    ep_rew_mean          | -18.6         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 137           |
|    time_elapsed         | 837           |
|    total_timesteps      | 70144         |
| train/                  |               |
|    approx_kl            | 2.6196823e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0821        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 110           |
|    n_updates            | 1360          |
|    policy_gradient_loss | -0.000352     |
|    value_loss           | 136           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.2          |
|    ep_rew_mean          | -19.1         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 138           |
|    time_elapsed         | 841           |
|    total_timesteps      | 70656         |
| train/                  |               |
|    approx_kl            | 1.4816294e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.0247        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 68.6          |
|    n_updates            | 1370          |
|    policy_gradient_loss | -0.000228     |
|    value_loss           | 102           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96           |
|    ep_rew_mean          | -16.6        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 139          |
|    time_elapsed         | 845          |
|    total_timesteps      | 71168        |
| train/                  |              |
|    approx_kl            | 0.0001788577 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.0263      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 12.7         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.000655    |
|    value_loss           | 12.9         |
------------------------------------------
Eval num_timesteps=71680, episode_reward=-42.84 +/- 53.31
Episode length: 79.88 +/- 49.08
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 79.9         |
|    mean_reward          | -42.8        |
| time/                   |              |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 9.723008e-07 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0177       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 671          |
|    n_updates            | 1390         |
|    policy_gradient_loss | -4.74e-05    |
|    value_loss           | 471          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.7     |
|    ep_rew_mean     | -15.9    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 140      |
|    time_elapsed    | 855      |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96.9        |
|    ep_rew_mean          | -15.4       |
| time/                   |             |
|    fps                  | 83          |
|    iterations           | 141         |
|    time_elapsed         | 860         |
|    total_timesteps      | 72192       |
| train/                  |             |
|    approx_kl            | 5.29096e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.1        |
|    explained_variance   | 0.0602      |
|    learning_rate        | 1.9e-05     |
|    loss                 | 139         |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.000179   |
|    value_loss           | 116         |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.5          |
|    ep_rew_mean          | -17.4         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 142           |
|    time_elapsed         | 865           |
|    total_timesteps      | 72704         |
| train/                  |               |
|    approx_kl            | 4.5797788e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0236        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 85.7          |
|    n_updates            | 1410          |
|    policy_gradient_loss | -5.81e-05     |
|    value_loss           | 247           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 95.1         |
|    ep_rew_mean          | -17.5        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 143          |
|    time_elapsed         | 870          |
|    total_timesteps      | 73216        |
| train/                  |              |
|    approx_kl            | 9.156263e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00991      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 17.9         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000707    |
|    value_loss           | 53           |
------------------------------------------
Eval num_timesteps=73728, episode_reward=-36.12 +/- 47.59
Episode length: 86.38 +/- 44.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 86.4        |
|    mean_reward          | -36.1       |
| time/                   |             |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 8.95292e-06 |
|    clip_fraction        | 0           |
|    clip_range           | 0.1         |
|    entropy_loss         | -1.1        |
|    explained_variance   | -0.0226     |
|    learning_rate        | 1.9e-05     |
|    loss                 | 46.1        |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.000102   |
|    value_loss           | 87.6        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 94.5     |
|    ep_rew_mean     | -17.3    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 144      |
|    time_elapsed    | 880      |
|    total_timesteps | 73728    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 93            |
|    ep_rew_mean          | -19.6         |
| time/                   |               |
|    fps                  | 83            |
|    iterations           | 145           |
|    time_elapsed         | 884           |
|    total_timesteps      | 74240         |
| train/                  |               |
|    approx_kl            | 1.5770318e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0138        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 99            |
|    n_updates            | 1440          |
|    policy_gradient_loss | -0.000398     |
|    value_loss           | 170           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.6          |
|    ep_rew_mean          | -17.8         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 146           |
|    time_elapsed         | 889           |
|    total_timesteps      | 74752         |
| train/                  |               |
|    approx_kl            | 2.7066562e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0194        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 193           |
|    n_updates            | 1450          |
|    policy_gradient_loss | -7.26e-05     |
|    value_loss           | 174           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 95.8         |
|    ep_rew_mean          | -17.1        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 147          |
|    time_elapsed         | 894          |
|    total_timesteps      | 75264        |
| train/                  |              |
|    approx_kl            | 2.778601e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0163       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 85.3         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.000107    |
|    value_loss           | 135          |
------------------------------------------
Eval num_timesteps=75776, episode_reward=-59.95 +/- 42.21
Episode length: 68.38 +/- 48.19
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 68.4          |
|    mean_reward          | -59.9         |
| time/                   |               |
|    total_timesteps      | 75776         |
| train/                  |               |
|    approx_kl            | 3.9169216e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.046         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 140           |
|    n_updates            | 1470          |
|    policy_gradient_loss | -0.000421     |
|    value_loss           | 147           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96       |
|    ep_rew_mean     | -16.6    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 148      |
|    time_elapsed    | 903      |
|    total_timesteps | 75776    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.5          |
|    ep_rew_mean          | -15.4         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 149           |
|    time_elapsed         | 908           |
|    total_timesteps      | 76288         |
| train/                  |               |
|    approx_kl            | 1.5642494e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0843        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 93.3          |
|    n_updates            | 1480          |
|    policy_gradient_loss | -0.00035      |
|    value_loss           | 98.1          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.4          |
|    ep_rew_mean          | -16.6         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 150           |
|    time_elapsed         | 912           |
|    total_timesteps      | 76800         |
| train/                  |               |
|    approx_kl            | 3.3481047e-07 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0221        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 93.2          |
|    n_updates            | 1490          |
|    policy_gradient_loss | -3.82e-05     |
|    value_loss           | 592           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 95.6         |
|    ep_rew_mean          | -15.4        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 151          |
|    time_elapsed         | 917          |
|    total_timesteps      | 77312        |
| train/                  |              |
|    approx_kl            | 7.371884e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0437       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 137          |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.000193    |
|    value_loss           | 164          |
------------------------------------------
Eval num_timesteps=77824, episode_reward=-53.83 +/- 42.92
Episode length: 80.62 +/- 43.87
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 80.6          |
|    mean_reward          | -53.8         |
| time/                   |               |
|    total_timesteps      | 77824         |
| train/                  |               |
|    approx_kl            | 1.8086517e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.19          |
|    learning_rate        | 1.9e-05       |
|    loss                 | 41            |
|    n_updates            | 1510          |
|    policy_gradient_loss | -0.000241     |
|    value_loss           | 44.3          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.3     |
|    ep_rew_mean     | -14.8    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 152      |
|    time_elapsed    | 927      |
|    total_timesteps | 77824    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 94.5          |
|    ep_rew_mean          | -16.4         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 153           |
|    time_elapsed         | 931           |
|    total_timesteps      | 78336         |
| train/                  |               |
|    approx_kl            | 5.3747906e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0254        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 41.6          |
|    n_updates            | 1520          |
|    policy_gradient_loss | -0.000473     |
|    value_loss           | 149           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.8          |
|    ep_rew_mean          | -15.6         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 154           |
|    time_elapsed         | 935           |
|    total_timesteps      | 78848         |
| train/                  |               |
|    approx_kl            | 1.4752499e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.072         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 45.3          |
|    n_updates            | 1530          |
|    policy_gradient_loss | -0.0002       |
|    value_loss           | 110           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 98.5         |
|    ep_rew_mean          | -14          |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 155          |
|    time_elapsed         | 940          |
|    total_timesteps      | 79360        |
| train/                  |              |
|    approx_kl            | 9.521842e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0655       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 133          |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00028     |
|    value_loss           | 158          |
------------------------------------------
Eval num_timesteps=79872, episode_reward=-57.62 +/- 51.61
Episode length: 60.25 +/- 51.90
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 60.2          |
|    mean_reward          | -57.6         |
| time/                   |               |
|    total_timesteps      | 79872         |
| train/                  |               |
|    approx_kl            | 2.5489135e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0952        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 45.5          |
|    n_updates            | 1550          |
|    policy_gradient_loss | -8.09e-05     |
|    value_loss           | 32.6          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.6     |
|    ep_rew_mean     | -15.1    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 156      |
|    time_elapsed    | 948      |
|    total_timesteps | 79872    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.2          |
|    ep_rew_mean          | -13.9         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 157           |
|    time_elapsed         | 953           |
|    total_timesteps      | 80384         |
| train/                  |               |
|    approx_kl            | 2.4159555e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0314       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 200           |
|    n_updates            | 1560          |
|    policy_gradient_loss | -0.000425     |
|    value_loss           | 79.6          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 99.1         |
|    ep_rew_mean          | -15.3        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 158          |
|    time_elapsed         | 957          |
|    total_timesteps      | 80896        |
| train/                  |              |
|    approx_kl            | 1.175527e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0903       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 78.3         |
|    n_updates            | 1570         |
|    policy_gradient_loss | -0.000191    |
|    value_loss           | 101          |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 98.2         |
|    ep_rew_mean          | -13.7        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 159          |
|    time_elapsed         | 962          |
|    total_timesteps      | 81408        |
| train/                  |              |
|    approx_kl            | 0.0001447975 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.085        |
|    learning_rate        | 1.9e-05      |
|    loss                 | 18           |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00072     |
|    value_loss           | 23.9         |
------------------------------------------
Eval num_timesteps=81920, episode_reward=-3.36 +/- 38.83
Episode length: 106.00 +/- 39.69
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 106           |
|    mean_reward          | -3.36         |
| time/                   |               |
|    total_timesteps      | 81920         |
| train/                  |               |
|    approx_kl            | 1.8561841e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.017         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 41            |
|    n_updates            | 1590          |
|    policy_gradient_loss | -0.000194     |
|    value_loss           | 328           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 98.1     |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 160      |
|    time_elapsed    | 974      |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 98.5         |
|    ep_rew_mean          | -12.9        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 161          |
|    time_elapsed         | 979          |
|    total_timesteps      | 82432        |
| train/                  |              |
|    approx_kl            | 6.053946e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0579       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 49.7         |
|    n_updates            | 1600         |
|    policy_gradient_loss | -7.73e-05    |
|    value_loss           | 53.6         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.3          |
|    ep_rew_mean          | -11.6         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 162           |
|    time_elapsed         | 984           |
|    total_timesteps      | 82944         |
| train/                  |               |
|    approx_kl            | 1.9116676e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.0726        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 27.1          |
|    n_updates            | 1610          |
|    policy_gradient_loss | -0.000284     |
|    value_loss           | 90.8          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 99           |
|    ep_rew_mean          | -12          |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 163          |
|    time_elapsed         | 988          |
|    total_timesteps      | 83456        |
| train/                  |              |
|    approx_kl            | 8.484116e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0484       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 23           |
|    n_updates            | 1620         |
|    policy_gradient_loss | -9.96e-05    |
|    value_loss           | 110          |
------------------------------------------
Eval num_timesteps=83968, episode_reward=-21.50 +/- 48.70
Episode length: 94.12 +/- 40.21
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 94.1          |
|    mean_reward          | -21.5         |
| time/                   |               |
|    total_timesteps      | 83968         |
| train/                  |               |
|    approx_kl            | 3.4914003e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0692        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 64.7          |
|    n_updates            | 1630          |
|    policy_gradient_loss | -0.000388     |
|    value_loss           | 155           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.9     |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    fps             | 83       |
|    iterations      | 164      |
|    time_elapsed    | 999      |
|    total_timesteps | 83968    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.9          |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 165           |
|    time_elapsed         | 1004          |
|    total_timesteps      | 84480         |
| train/                  |               |
|    approx_kl            | 4.5507797e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.123         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 22.5          |
|    n_updates            | 1640          |
|    policy_gradient_loss | -0.000357     |
|    value_loss           | 42            |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.3          |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 166           |
|    time_elapsed         | 1008          |
|    total_timesteps      | 84992         |
| train/                  |               |
|    approx_kl            | 2.3462926e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.014         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 34.9          |
|    n_updates            | 1650          |
|    policy_gradient_loss | -0.000387     |
|    value_loss           | 94            |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 99           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 167          |
|    time_elapsed         | 1012         |
|    total_timesteps      | 85504        |
| train/                  |              |
|    approx_kl            | 4.652189e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00688      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 16.2         |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.000102    |
|    value_loss           | 55.8         |
------------------------------------------
Eval num_timesteps=86016, episode_reward=-44.93 +/- 48.56
Episode length: 78.88 +/- 50.46
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 78.9          |
|    mean_reward          | -44.9         |
| time/                   |               |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 1.5953905e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0827        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 169           |
|    n_updates            | 1670          |
|    policy_gradient_loss | -0.000329     |
|    value_loss           | 126           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99       |
|    ep_rew_mean     | -13.5    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 168      |
|    time_elapsed    | 1022     |
|    total_timesteps | 86016    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -12.4        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 169          |
|    time_elapsed         | 1026         |
|    total_timesteps      | 86528        |
| train/                  |              |
|    approx_kl            | 2.231449e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0668       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 131          |
|    n_updates            | 1680         |
|    policy_gradient_loss | -9.25e-05    |
|    value_loss           | 191          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 170           |
|    time_elapsed         | 1031          |
|    total_timesteps      | 87040         |
| train/                  |               |
|    approx_kl            | 0.00018481642 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0212        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 10.8          |
|    n_updates            | 1690          |
|    policy_gradient_loss | -0.00134      |
|    value_loss           | 9.16          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 101          |
|    ep_rew_mean          | -11.7        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 171          |
|    time_elapsed         | 1035         |
|    total_timesteps      | 87552        |
| train/                  |              |
|    approx_kl            | 7.603271e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.000737    |
|    learning_rate        | 1.9e-05      |
|    loss                 | 11.2         |
|    n_updates            | 1700         |
|    policy_gradient_loss | -0.000354    |
|    value_loss           | 27.6         |
------------------------------------------
Eval num_timesteps=88064, episode_reward=-48.46 +/- 52.01
Episode length: 61.12 +/- 59.88
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 61.1         |
|    mean_reward          | -48.5        |
| time/                   |              |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 6.160699e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.132        |
|    learning_rate        | 1.9e-05      |
|    loss                 | 30.9         |
|    n_updates            | 1710         |
|    policy_gradient_loss | -0.000167    |
|    value_loss           | 31.4         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 103      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 172      |
|    time_elapsed    | 1043     |
|    total_timesteps | 88064    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -9.61         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 173           |
|    time_elapsed         | 1048          |
|    total_timesteps      | 88576         |
| train/                  |               |
|    approx_kl            | 5.6056306e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0958        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 151           |
|    n_updates            | 1720          |
|    policy_gradient_loss | -0.000202     |
|    value_loss           | 97.9          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 103           |
|    ep_rew_mean          | -8.93         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 174           |
|    time_elapsed         | 1052          |
|    total_timesteps      | 89088         |
| train/                  |               |
|    approx_kl            | 2.0329608e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0904        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 192           |
|    n_updates            | 1730          |
|    policy_gradient_loss | -8.17e-05     |
|    value_loss           | 192           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 175           |
|    time_elapsed         | 1056          |
|    total_timesteps      | 89600         |
| train/                  |               |
|    approx_kl            | 1.6350998e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0936        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 74.4          |
|    n_updates            | 1740          |
|    policy_gradient_loss | -0.000364     |
|    value_loss           | 120           |
-------------------------------------------
Eval num_timesteps=90112, episode_reward=-37.33 +/- 51.11
Episode length: 81.38 +/- 43.29
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 81.4          |
|    mean_reward          | -37.3         |
| time/                   |               |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 1.8833904e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0358        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 287           |
|    n_updates            | 1750          |
|    policy_gradient_loss | -0.000396     |
|    value_loss           | 168           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    fps             | 84       |
|    iterations      | 176      |
|    time_elapsed    | 1066     |
|    total_timesteps | 90112    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 101           |
|    ep_rew_mean          | -11.7         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 177           |
|    time_elapsed         | 1070          |
|    total_timesteps      | 90624         |
| train/                  |               |
|    approx_kl            | 1.4503603e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | -0.0667       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 10.7          |
|    n_updates            | 1760          |
|    policy_gradient_loss | -0.000196     |
|    value_loss           | 32.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 102           |
|    ep_rew_mean          | -13           |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 178           |
|    time_elapsed         | 1075          |
|    total_timesteps      | 91136         |
| train/                  |               |
|    approx_kl            | 1.8644496e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.088         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 165           |
|    n_updates            | 1770          |
|    policy_gradient_loss | -0.000462     |
|    value_loss           | 174           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 100          |
|    ep_rew_mean          | -14          |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 179          |
|    time_elapsed         | 1080         |
|    total_timesteps      | 91648        |
| train/                  |              |
|    approx_kl            | 7.538544e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.00983      |
|    learning_rate        | 1.9e-05      |
|    loss                 | 14.4         |
|    n_updates            | 1780         |
|    policy_gradient_loss | -0.000571    |
|    value_loss           | 10.1         |
------------------------------------------
Eval num_timesteps=92160, episode_reward=7.97 +/- 13.26
Episode length: 121.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 121          |
|    mean_reward          | 7.97         |
| time/                   |              |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 8.797622e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0581       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 27.5         |
|    n_updates            | 1790         |
|    policy_gradient_loss | -9.99e-05    |
|    value_loss           | 253          |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.5     |
|    ep_rew_mean     | -15      |
| time/              |          |
|    fps             | 84       |
|    iterations      | 180      |
|    time_elapsed    | 1092     |
|    total_timesteps | 92160    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 99.9         |
|    ep_rew_mean          | -14.6        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 181          |
|    time_elapsed         | 1096         |
|    total_timesteps      | 92672        |
| train/                  |              |
|    approx_kl            | 4.323316e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0517       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 172          |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.000145    |
|    value_loss           | 145          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.4          |
|    ep_rew_mean          | -15.7         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 182           |
|    time_elapsed         | 1101          |
|    total_timesteps      | 93184         |
| train/                  |               |
|    approx_kl            | 1.1841534e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0984        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 124           |
|    n_updates            | 1810          |
|    policy_gradient_loss | -0.000222     |
|    value_loss           | 86.7          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 97.9          |
|    ep_rew_mean          | -16.7         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 183           |
|    time_elapsed         | 1105          |
|    total_timesteps      | 93696         |
| train/                  |               |
|    approx_kl            | 3.2462412e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0156        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 147           |
|    n_updates            | 1820          |
|    policy_gradient_loss | -0.000139     |
|    value_loss           | 210           |
-------------------------------------------
Eval num_timesteps=94208, episode_reward=-41.90 +/- 49.66
Episode length: 83.88 +/- 44.02
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 83.9          |
|    mean_reward          | -41.9         |
| time/                   |               |
|    total_timesteps      | 94208         |
| train/                  |               |
|    approx_kl            | 1.1094846e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0424        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 54.9          |
|    n_updates            | 1830          |
|    policy_gradient_loss | -0.000105     |
|    value_loss           | 93.9          |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.3     |
|    ep_rew_mean     | -14.8    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 184      |
|    time_elapsed    | 1115     |
|    total_timesteps | 94208    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.9          |
|    ep_rew_mean          | -15.3         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 185           |
|    time_elapsed         | 1120          |
|    total_timesteps      | 94720         |
| train/                  |               |
|    approx_kl            | 1.5578582e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.133         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 201           |
|    n_updates            | 1840          |
|    policy_gradient_loss | -0.000327     |
|    value_loss           | 105           |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 98.7          |
|    ep_rew_mean          | -15.5         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 186           |
|    time_elapsed         | 1125          |
|    total_timesteps      | 95232         |
| train/                  |               |
|    approx_kl            | 7.0537208e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.013         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 321           |
|    n_updates            | 1850          |
|    policy_gradient_loss | -0.000209     |
|    value_loss           | 230           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 97.7         |
|    ep_rew_mean          | -16.6        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 187          |
|    time_elapsed         | 1129         |
|    total_timesteps      | 95744        |
| train/                  |              |
|    approx_kl            | 7.876521e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.1         |
|    explained_variance   | 0.0665       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 23.7         |
|    n_updates            | 1860         |
|    policy_gradient_loss | -0.000717    |
|    value_loss           | 78.7         |
------------------------------------------
Eval num_timesteps=96256, episode_reward=-15.57 +/- 47.93
Episode length: 101.88 +/- 33.54
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 102           |
|    mean_reward          | -15.6         |
| time/                   |               |
|    total_timesteps      | 96256         |
| train/                  |               |
|    approx_kl            | 2.4123583e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0652        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 91.5          |
|    n_updates            | 1870          |
|    policy_gradient_loss | -8.85e-05     |
|    value_loss           | 125           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 99.1     |
|    ep_rew_mean     | -15.3    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 188      |
|    time_elapsed    | 1140     |
|    total_timesteps | 96256    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.6          |
|    ep_rew_mean          | -14.5         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 189           |
|    time_elapsed         | 1144          |
|    total_timesteps      | 96768         |
| train/                  |               |
|    approx_kl            | 1.9762316e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.089         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 107           |
|    n_updates            | 1880          |
|    policy_gradient_loss | -0.000433     |
|    value_loss           | 97.3          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 99.6          |
|    ep_rew_mean          | -14.1         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 190           |
|    time_elapsed         | 1149          |
|    total_timesteps      | 97280         |
| train/                  |               |
|    approx_kl            | 2.1684216e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.0534        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 146           |
|    n_updates            | 1890          |
|    policy_gradient_loss | -0.000388     |
|    value_loss           | 84.2          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.8          |
|    ep_rew_mean          | -16.8         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 191           |
|    time_elapsed         | 1153          |
|    total_timesteps      | 97792         |
| train/                  |               |
|    approx_kl            | 6.0866587e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.1          |
|    explained_variance   | 0.191         |
|    learning_rate        | 1.9e-05       |
|    loss                 | 30.8          |
|    n_updates            | 1900          |
|    policy_gradient_loss | -0.000143     |
|    value_loss           | 27.8          |
-------------------------------------------
Eval num_timesteps=98304, episode_reward=-28.28 +/- 51.30
Episode length: 102.00 +/- 38.82
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 102          |
|    mean_reward          | -28.3        |
| time/                   |              |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 8.549425e-06 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0431       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 103          |
|    n_updates            | 1910         |
|    policy_gradient_loss | -0.000218    |
|    value_loss           | 189          |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.5     |
|    ep_rew_mean     | -16.8    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 192      |
|    time_elapsed    | 1164     |
|    total_timesteps | 98304    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 96.2          |
|    ep_rew_mean          | -18.4         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 193           |
|    time_elapsed         | 1168          |
|    total_timesteps      | 98816         |
| train/                  |               |
|    approx_kl            | 1.2252131e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | -0.0442       |
|    learning_rate        | 1.9e-05       |
|    loss                 | 23.7          |
|    n_updates            | 1920          |
|    policy_gradient_loss | -0.000199     |
|    value_loss           | 75.4          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 96.6         |
|    ep_rew_mean          | -18.4        |
| time/                   |              |
|    fps                  | 84           |
|    iterations           | 194          |
|    time_elapsed         | 1172         |
|    total_timesteps      | 99328        |
| train/                  |              |
|    approx_kl            | 3.842765e-05 |
|    clip_fraction        | 0            |
|    clip_range           | 0.1          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0806       |
|    learning_rate        | 1.9e-05      |
|    loss                 | 63.2         |
|    n_updates            | 1930         |
|    policy_gradient_loss | -0.00037     |
|    value_loss           | 98.1         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 95.6          |
|    ep_rew_mean          | -19.7         |
| time/                   |               |
|    fps                  | 84            |
|    iterations           | 195           |
|    time_elapsed         | 1177          |
|    total_timesteps      | 99840         |
| train/                  |               |
|    approx_kl            | 6.2432024e-05 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.0243        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 60            |
|    n_updates            | 1940          |
|    policy_gradient_loss | -0.000707     |
|    value_loss           | 87.9          |
-------------------------------------------
Eval num_timesteps=100352, episode_reward=-18.94 +/- 68.33
Episode length: 68.12 +/- 53.08
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 68.1          |
|    mean_reward          | -18.9         |
| time/                   |               |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 1.4498364e-06 |
|    clip_fraction        | 0             |
|    clip_range           | 0.1           |
|    entropy_loss         | -1.09         |
|    explained_variance   | 0.0804        |
|    learning_rate        | 1.9e-05       |
|    loss                 | 206           |
|    n_updates            | 1950          |
|    policy_gradient_loss | -3.97e-05     |
|    value_loss           | 229           |
-------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.7     |
|    ep_rew_mean     | -19.1    |
| time/              |          |
|    fps             | 84       |
|    iterations      | 196      |
|    time_elapsed    | 1186     |
|    total_timesteps | 100352   |
---------------------------------
 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100,352/100,000  [ 0:19:39 < 0:00:00 , 76 it/s ]
Final model saved to models/scarlet-butterfly-16/final_model
